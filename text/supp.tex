%!TEX root = anderson-etal-blackswan-timeseries.tex

\begin{centering}
\LARGE
Supporting Information\\[1.0em]
\end{centering}

\section{Data selection}

We applied the following data selection and quality-control rules to the Global
Population Dynamics Database (GPDD):

\begin{enumerate}

\item To remove populations with unreliable population indices that could be
  strongly confounded with economics and sampling effort, we removed all
  populations with a sampling protocol listed as \texttt{harvest} as well
  populations with the words \texttt{harvest} or \texttt{fur} in the cited
  reference title.

\item We removed all populations with uneven sampling intervals, i.e.\ we removed
  populations that didn't have a constant difference between the ``decimal year
  begin'' and ``decimal year end'' columns.

\item We removed all populations rated as $< 2$ in the GPDD quality assessment
  (on a scale of $1$ to $5$, with $1$ being the lowest quality data)
  \citep[following][]{sibly2005, ziebarth2010}

\item Populations with negative abundance values were assumed to be log10
  values and transformed by taking $10$ to the power of the recorded abundance.
  In many cases this was noted for the population, but not in all cases. We
  inspected each of these \totalAssumedLog~time series to make sure our
  assumption made sense.

\item We filled in all missing time steps with \texttt{NA} values and imputed
  single missing values with the geometric mean of the previous and following
  values. We chose a geometric mean to be linear on the log scale that the
  Gompertz and Ricker-logistic models were fitted on.

\item We filled in single recorded values of zero with the lowest non-zero
  value in the time series \citep[following][]{brook2006a}. This assumes that
  single values of zero result from abundance being low enough that censusing
  overlooked individuals that were actually present. We turned multiple zero
  values in a row into \texttt{NA} values. This implies that multiple zero
  values were either censusing errors or caused by emigration. Regardless, our
  population models were fitted on a multiplicative (log) scale and so could
  not account for zero abundance. To avoid distorting the original data too
  strongly, we removed populations in which we filled in more than four zeros.

\item We removed all populations without at least four unique values
  \citep[following][]{brook2006a}.

\item We removed all populations with four or more identical values in a row
  since these suggest either recording error or extrapolation between two
  observations.

\item We then wrote an algorithm to find the longest unbroken window of
  abundance (no \texttt{NA}s) with at least $20$ time steps in each population
  time series. If there were any populations with multiple windows of identical
  length, we took the most recent window. This is a longer window than used in
  some previous analyses \citep[e.g.][]{brook2006a}, but since our model
  attempts to capture the shape of the distribution tails, our model requires
  more data.

\item Finally, we removed GPDD Main ID \texttt{20531}, which we noticed was
  a duplicate of \texttt{10139} (a heron population). We removed a limited
  number of populations from class Angiospermopsida and Bacillariophyceae to
  focus the taxonomy in our analysis. We also removed any populations with an
  \texttt{Unknown} taxonomic class.

\end{enumerate}

\noindent
We provide a supplemental figure of all the time series included in our analysis
and indicate which values were interpolated (\percImputedPops\% of populations
had at least one point interpolated and only \percImputedPoints\% of the total
observations were interpolated) (Fig.~\ref{fig:all-ts}). Table S1 shows the
final taxonomic breakdown and the number of populations with interpolated
values.

\section{Details on the heavy-tailed Gompertz probability model}

For the Gompertz model, our weakly-informative priors (Fig.~\ref{fig:priors}) were:
\begin{align*}
b &\sim \mathrm{Uniform}(-1, 2)\\ \lambda &\sim \mathrm{Normal}(0, 10^2)\\
\sigma &\sim \mathrm{Half\mhyphen Cauchy} (0, 2.5)\\ \nu &\sim
\mathrm{Truncated\mhyphen Exponential}(0.01, \mathrm{min.} = 2). \end{align*}
Our prior on $b$ was uninformative between values of $-1$ and $2$. We would not
expect values of $b$ with levels of density dependence as low as $-1$ (very
strong inverse density dependence), nor would we generally expect values above
$1$. We allowed values of $b$ above $1$ to allow for non-stationary time series
of growth rates. The estimates of $b$ were well within these bounds. Our prior
on $\lambda$ was very weakly informative within the range of expected values
for population growth and is similar to the default priors suggested by
\citet{gelman2008d} for intercepts of regression models. Our Half-Cauchy prior
on $\sigma$ follows \citet{gelman2006c} and \citet{gelman2008d} and the scale
parameter of $2.5$ is based on our expected range of the value in nature from
previous studies \citep[e.g.][]{connors2014}. In our testing of a subsample of
populations, our parameter estimates were not qualitatively changed by
switching to an uninformative uniform prior on $\sigma$, but the weakly
informative Half-Cauchy prior substantially sped up chain convergence.

Our prior on $\nu$ was based on \citet{fernandez1998}. They chose an
exponential rate parameter of $0.1$. We chose a less informative rate parameter
of $0.01$ and truncated the distribution at $2$, since at $\nu < 2$ the
variance of the t distribution is undefined. This prior gives only a $7.7$\%
probability that $\nu < 10$ but constrains the sampling sufficiently to avoid
wandering off towards infinity --- above approximately $\nu = 20$ the
t distribution is so similar to the normal distribution
(Fig.~\ref{fig:didactic}) that time series of the length considered here are
unlikely to be informative about the precise value of $\nu$. In the scenario
where the data are uninformative about heavy tails
(e.g.~Fig.~\ref{fig:didactic}e,~h), the posterior will approximately match the
prior (prior median $= 71$, mean $= 102$) and the metrics used in our paper
(e.g.~Pr$(\nu < 10) > 0.5$) are unlikely to flag the population as heavy
tailed.

We fitted our models with Stan 2.4.0 \citep{stan-manual2014}, and R 3.1.1
\citep{r2014}. We began with four chains and $2000$ iterations, discarding the
first $1000$ as warm up (i.e.~4000 total samples). If $\hat{R}$ (the potential
scale reduction factor --- a measure of chain convergence) was greater than
$1.05$ for any parameter or the minimum effective sample size,
$n_\mathrm{eff}$, (a measure of the effective number of uncorrelated samples)
for any parameter was less than $200$, we doubled both the total iterations
and warm up period and sampled from the model again. These thresholds are in
excess of the minimums recommended by \citet{gelman2006a} of $\hat{R} < 1.1$
and effective sample size $> 100$ for reliable point estimates and confidence
intervals. In the majority of cases our minimum thresholds were greatly
exceeded. We continued this procedure up to $8000$ iterations ($16000$ total
samples) by which all chains were deemed to have sufficiently converged. These
chain lengths may seem low to those familiar with software such as WinBUGS or
JAGS, but the No-U-Turn Hamiltonian Markov chain Monte Carlo Sampler in Stan
generally requires far fewer iterations to obtain equivalent effective sample
sizes \citep{stan-manual2014}.


\section{Alternative population models}

We fit four alternative population models to the time-series data to check how
they would influence our conclusions. Our alternative models allowed for
autocorrelation in the residuals, assumed no density dependence, allowed for
observation error, or assumed a Ricker-logistic functional form. The range of
percentages of black swans by taxonomic class cited in the abstract and results
are based on lower and upper limits across our main Gompertz model and these
four alternative models.

\subsection{Autocorrelated residuals}

We considered a version of the Gompertz model in which an autoregressive
parameter was fitted to the process noise residuals:
\begin{align*}
x_t &= \lambda + b x_{t-1} + \epsilon_t\\
\epsilon_t &\sim \mathrm{Student\mhyphen t}(\nu, \phi \epsilon_{t-1}, \sigma).
\end{align*}
In addition to the parameters in the original Gompertz model, we estimate an
additional parameter $\phi$, which represents the dependence of
subsequent residuals. Based on the results of previous analyses with the GPDD
\citep[e.g.][]{connors2014} and the chosen priors in previous analyses
\citep[e.g.][]{thorson2014a} and to greatly speed up chain convergence when
running our model across all populations, we placed a weakly informative prior
on $\phi$ that assumed the greatest probability density near zero with the
reduced possibility of $\phi$ being near $-1$ or $1$. Specifically, we chose
$\phi \sim \mathrm{Truncated\mhyphen Normal}(0, 1, \mathrm{min.} = -1,
\mathrm{max.} = 1)$. The MCMC chains did
not converge for \modelsNoConvergeAROne\ populations according to
our criteria ($\widehat{R} < 1.05, n_\mathrm{eff}
> 200$) after 8000 iterations of four chains. This included only
\modelsNoConvergeAROneHeavyBase\ populations in which
Pr($\nu < 10$) $> 0.5$ categorized them as heavy in the main Gompertz model.
We did not include these models in Fig.~\ref{fig:alt}.
\textit{TODO perhaps I should go up to 16,000 so that more converge.}

\subsection{Assumed density independence}\label{assumed-density-independence}

We fit a simplified version of the Gompertz model in which the density
dependence parameter $b$ was fixed at $1$ (density independent). This is
equivalent to fitting a random walk model (with drift) to the $\log$ abundances
or assuming the growth rates are drawn from a stationary distribution. The
model was as follows:
\begin{align*}
x_t &= \lambda + x_{t-1} + \epsilon_t\\
\epsilon &\sim \mathrm{Student\mhyphen t}(\nu, 0, \sigma).
\end{align*}
We fit this model for three reasons: (1) it is computationally simpler and so
provides a check that our more complicated full Gompertz model was obtaining
reasonable estimates of $\nu$, (2) it provides a test of whether density
dependence was systematically affecting our perception of heavy tails, (3) it
matches how some previous authors have modelled heavy tails without accounting
for density dependence \citep{segura2013}.

\subsection{Assumed observation error}

Observation error can bias parameter estimates \citep[e.g.][]{knape2012} and is
known to affect the ability to detect extreme events \citep{ward2007}. In our
main analysis, we fit a model that ignored observation error. One way to
account for observation error would be to fit a full state-space model that
simultaneously estimates the magnitude of process noise and observation error.
However, simultaneously estimating observation and process noise is
a challenging problem (e.g.\ because the observation and process noise
parameters tend to negatively covary in model fitting) and is known to
sometimes result in identifiability issues with the Gompertz population model
\citep{knape2008}. Furthermore, our model was applied to hundreds of time
series, often of short length (as few as 20 time steps) and our model estimates
an additional parameter --- the shape of the process deviation tails ---
potentially making identifiability and computational issues even greater.
Therefore, we considered a version of the base Gompertz model that allowed for
a fixed level of observation error:
\begin{align*}
U_t &= \lambda + b U_{t-1} + \epsilon_t\\
x_t &\sim \mathrm{Normal}(U_t, \sigma_\mathrm{obs}^2)\\
\epsilon_t &\sim \mathrm{Student\mhyphen t}(\nu, 0, \sigma_\mathrm{proc}),
\end{align*}
where $U$ represents the unobserved state vector, $\sigma_\mathrm{obs}$
represents the standard deviation of observation error (on a log scale), and
$\sigma_\mathrm{proc}$ represent the process noise scale parameter. We set
$\sigma_\mathrm{obs}$ to $0.2$, which represents the upper limit of values often
used in simulation analyses \citep[e.g.][]{valpine2002, thorson2014b}.

\subsection{Ricker-logistic}

We also fitted a Ricker-logistic model:
\begin{align*}
x_t &= x_{t-1} + r_{\mathrm{max}}\left(1 - \frac{N_{t-1}}{K}\right) + \epsilon_t\\
\epsilon_t &\sim \mathrm{Student\mhyphen t}(\nu, 0, \sigma),
\end{align*}
where $r_\mathrm{max}$ represents the theoretical maximum population growth
rate that is obtained when $N$ (abundance) $= 0$. The parameter $K$ represents
the carrying capacity and, as before, $x_t$ represents the $\log$ transformed
abundance at time $t$. The Ricker-logistic model assumes a linear decrease in
population growth rate ($x_t - x_{t-1}$) with increases in abundance ($N_t$).
In contrast, the Gompertz model assumes a linear decrease in population growth
rate with increases in \textit{log} abundance ($x_t$) (REF).

To fit the Ricker-logistic models, we chose a prior on $K$ uniform between zero
and twice the maximum observed abundance (\citet{clark2010} chose uniform
between zero and maximum observed, which is more informative). We set the prior
on $r_\mathrm{max}$ as uniform between 0 and 20 as in \citet{clark2010}. We used
the same priors on $\nu$ and $\sigma$ as in the Gompertz model.

\section{Simulation testing the model}

We performed two types of simulation testing. First, we tested how easily the
Student-t distribution $\nu$ parameter could be recovered given different true
values of $\nu$ and different sample sizes. Second, we tested the ability of the
heavy-tailed Gompertz model to obtain unbiased parameter estimates of $\nu$
given that a set of process deviations was provided in which the effective
$\nu$ value was close to the true $\nu$ value.

We separated our simulation into these two components to avoid confounding two
issues. (1) With smaller sample sizes, there may not be a stochastic draw from
the tails of a distribution. In that case, no model, no matter how perfect,
will be able to detect the shape of the tails. (2) Complex models may return
biased parameter estimates if there are conceptual, computational, or coding
errors. Our first simulation tested the first issue and our second simulation
tested the latter. In general, our simulations show that, if anything, our
model under predicts the magnitude and probability of heavy tailed events ---
especially given the length of the time series in the GPDD.

\subsection{Estimating $\nu$ from a stationary t distribution}

First, we tested the ability to estimate $\nu$ given different true values of
$\nu$ and different sample sizes. We took stochastic draws from t distributions with
different $\nu$ values ($\nu = 3, 5, 10,$ and $10^6$ [$\approx$ normal]), with
central tendency parameters of $0$, and scale parameters of $1$. We started with
$1600$ stochastic draws and then fitted the models again at the first $800, 400,
200, 100, 50,$ and $25$ draws. Each time we recorded the posterior samples of
$\nu$.

We found that we could consistently and precisely recover median posterior
estimates of $\nu$ near the true value of $\nu$ with large samples ($\ge 200$)
(Fig.~\ref{fig:sim-gompertz} upper panels). At smaller samples we could still
usually qualitatively distinguish heavy from not-heavy tails, but the model
tended to underestimate how heavy the tails were. At the same time, at smaller
sample sizes, the model tended to overestimate how large the scale parameter
was (Fig.~\ref{fig:sim-gompertz} lower panels).

\subsection{Heavy-tailed Gompertz model simulations}

In the second part of our simulation testing, we tested the ability of the
heavy-tailed Gompertz model to obtain unbiased parameter estimates 
when the process noise was chosen so that appropriate tail events were present.
To generate these process deviations for the $\nu = 3$ and $\nu = 5$ scenarios, we
repeatedly drew proposed candidate process deviations and estimated the central
tendency, scale, and $\nu$ values each time. We recorded when $\hat{\nu}$
(median of the posterior) was within $0.2$ CVs (coefficient of variations) of
the true $\nu$ value and used this set of random seed values in our Gompertz
simulation. The following simplified R code illustrates this procedure 
(the actual code is available at \url{https://github.com/seananderson/heavy-tails}):

\begin{footnotesize}
\begin{verbatim}
get_effective_nu_seeds <- function(nu_true = 5, cv = 0.2, N = 50, seed_N = 20) {
  # nu_true: The true nu value
  # cv:      The permitted effective nu coefficient of variation
  # N:       The length of time series
  # seed_N:  The number of seed values to generate
  seeds <- numeric(length = seed_N)
  seed_value <- 0
  for (i in seq_len(seed_N)) {
    nu_close <- FALSE
    while (!nu_close) {
      seed_value <- seed_value + 1
      set.seed(i)
      y <- rt(N, df = nu_true)
      sm <- rstan::stan(... # fit the Stan model here
      med_nu_hat <- median(rstan::extract(sm, pars = "nu")[[1]])
      if (med_nu_hat > (nu_true - cv) & med_nu_hat < (nu_true + cv)) {
        nu_close <- TRUE
        seeds[i] <- seed_value
      }
    }
  }
  seeds
}
nu_3_seeds_N50 <- get_effective_nu_seeds(nu_true = 3)
nu_5_seeds_N50 <- get_effective_nu_seeds(nu_true = 5)
\end{verbatim}
\end{footnotesize}

We then fitted our Gompertz models to the simulated datasets with all
parameters (except $\nu$) set near the median values estimated in the GPDD. We
repeated this with $50$ and $100$ samples without observation error, $50$
samples with observation error ($\sigma_\mathrm{obs} = 0.2$), and $50$ samples
with the same observation error and a Gompertz model that allowed for correctly
specified observation error magnitude.

Our results show that the Gompertz model can recapture the true value of $\nu$
when the process noise was chosen so that appropriate tail events were present
(Figs~\ref{fig:sim-gompertz} and \ref{fig:sim-gompertz-boxplots}, red and green
symbols in the top rows). Likewise, the other Gompertz parameters were
estimated without any systematic bias (Figs~\ref{fig:sim-gompertz} and
\ref{fig:sim-gompertz-boxplots}, red and green symbols). The addition of
observation error caused the model to tend to underestimate the degree of
heavy-tailedness, overestimate the magnitude of process noise, somewhat
overestimate $\lambda$, and overestimate density dependence (blue symbols in
Figs~\ref{fig:sim-gompertz} and \ref{fig:sim-gompertz-boxplots}). The
overestimation of density dependence with observation error is a known
phenomenon \citep{knape2012}. Fitting a model with correctly specified
observation error made marginal improvements to model bias (purple symbols in
Figs~\ref{fig:sim-gompertz} and \ref{fig:sim-gompertz-boxplots}).

When converting the posterior distributions of $\nu$ into Pr($\nu < 10$), the
models distinguished heavy and not-heavy tails reasonably well. Without
observation error, and using a probability of $0.5$ as a threshold, the model
correctly classified all simulated systems with normally distributed process
noise as not heavy tailed. The model would have miscategorized only one of $40$
simulations at $\nu = 5$ across a sample size of $50$ or $100$ data points
(Fig.~\ref{fig:sim-prob}, upper panels). The model would have correctly
categorized all cases where the process noise was not heavy tailed (indicated
as ``$\nu =$ infinity'' in Fig.~\ref{fig:sim-prob}) and all cases where $\nu
= 3$. With $0.2$ standard deviations of observation error, the model still
categorized \obsErrorNuFivePerc\% of cases as heavy tailed when $\nu = 5$ and
all cases where $\nu = 3$. Allowing for observation error made little
improvement to the detection of heavy tails (Fig.~\ref{fig:sim-prob},
lower-left vs.\ lower-right panel). Therefore, we chose to focus on the simpler
model without observation error in the main text, particularly given that the
true magnitude of observation error was unknown in the empirical data.

\section{Modelling covariates of heavy-tailed dynamics}

We fitted a multilevel beta regression model to the predicted probability of
heavy tails, Pr($\nu < 10$), to investigate potential covariates of heavy-tailed
dynamics. The beta distribution is useful when response data range on
a continuous scale between zero and one. We used a logit link function as is
typically used in logistic regression. The model was as follows:
\begin{align*}
\mathrm{Pr}(\nu_i < 0.5) &\sim \mathrm{Beta}(A_i, B_i)\\
\mu_i &= \mathrm{logit}^{-1}(\alpha
  + \alpha^\mathrm{class}_{j[i]}
  + \alpha^\mathrm{order}_{k[i]}
  + \alpha^\mathrm{species}_{l[i]}
  + X_i \beta),
  \: \text{for } i = 1, \dots, 617\\
A_i &= \phi_\mathrm{disp} \mu_i\\
B_i &= \phi_\mathrm{disp} (1 - \mu_i)\\
\alpha^\mathrm{class}_j &\sim
  \mathrm{Normal}(0, \sigma^2_{\alpha \; \mathrm{class}}),
  \: \text{for } j = 1, \dots, 6\\
\alpha^\mathrm{order}_k &\sim
  \mathrm{Normal}(0, \sigma^2_{\alpha \; \mathrm{order}}),
  \: \text{for } k = 1, \dots, 38\\
\alpha^\mathrm{species}_l &\sim
  \mathrm{Normal}(0, \sigma^2_{\alpha \; \mathrm{species}}),
  \: \text{for } l = 1, \dots, 301,
\end{align*}
where $A$ and $B$ represent the beta distribution shape parameters; $\mu_i$
represents the predicted value for population $i$, class $j$, order $k$, and
species $l$; $\phi_\mathrm{disp}$ represents the dispersion parameter; and $X_i$
represents a vector of predictors (such as lifespan) for population $i$ with
associated $\beta$ coefficients. The intercepts are allowed to vary from the
overall intercept $\alpha$ by taxonomic class ($\alpha^\mathrm{class}_j$),
taxonomic order ($\alpha^\mathrm{order}_k$), and species
($\alpha^\mathrm{species}_l$) with standard deviations $\sigma_{\alpha \;
  \mathrm{class}}$, $\sigma_{\alpha \; \mathrm{order}}$, and $\sigma_{\alpha \;
  \mathrm{species}}$. Where possible, we also allowed for error distributions
around the predictors by incorporating the standard deviation of the posterior
samples for the Gompertz parameters $\lambda$, $b$, and $\log \sigma$ around the
mean point value as normal distributions (not shown in the above equation).

We log transformed $\sigma$, time-series length, and lifespan to match the way
they are visually represented in Fig.~\ref{fig:correlates} and to make the
relationship approximately linear on the logit-transformed response scale. All
input variables were standardized by subtracting their mean and dividing by two
standard deviations to make their coefficients comparable in magnitude
\citep{gelman2008c}. We excluded body length as a covariate because it was
highly correlated with lifespan, and lifespan exhibited more overlap across
taxonomy than body length. Lifespan is also more directly related to time and
potential mechanisms driving black swan dynamics.

We incorporated weakly informative priors into our model: $\mathrm{Cauchy}(0,
10)$ on the global intercept $\alpha$, $\mathrm{Half\mhyphen Cauchy}(0, 2.5)$ on
all standard deviation parameters, $\mathrm{Half\mhyphen Cauchy}(0, 10)$ on the
dispersion parameter $\phi_\mathrm{disp}$, and $\mathrm{Cauchy}(0, 2.5)$ on all
other parameters \citep{gelman2006c, gelman2008d}. Compared to normal priors,
the Cauchy priors concentrate more probability density around expected parameter
values while allowing for a higher probability density far into the tails, thereby
allowing the data to dominate the posterior more strongly if it disagrees with
the prior. Our conclusions were not qualitatively changed by using uniform
priors. We fitted our models with 5000 total iterations per chain, 2500 warm-up
iterations, four chains, and discarding every second sample to save memory. We
checked for chain convergence visually and with the same criteria as before
($\widehat{R} < 1.05$ and $n_\mathrm{eff} >200$ for all parameters).

To derive taxonomic-order-level estimates of the probability of heavy tails
accounting for time-series length (Fig \ref{fig:order-estimates}), we fitted
a separate multilevel model with the same structure but with only $\log$
time-series length as a predictor. (In this case, we did not want to control
for intrinsic population characteristics such as density dependence.) Since our
predictors were centered by subtracting their mean value, we obtained
order-level estimates of the probability of heavy tails at mean log time-series
length by adding the posteriors for $\alpha$, $\alpha^\mathrm{class}_j$, and
$\alpha^\mathrm{order}_k$.

\bibliographystyle{ecologyletters}
\bibliography{/Users/seananderson/Dropbox/tex/jshort,/Users/seananderson/Dropbox/tex/ref3}

% ------------------------------
% Supplemental Tables
% ------------------------------

\clearpage
\renewcommand{\thetable}{S\arabic{table}}
\setcounter{table}{0}
\input{../analysis/stat-table}
\clearpage

% ------------------------------
% Supplemental Figures
% ------------------------------

\renewcommand{\thefigure}{S\arabic{figure}}
\setcounter{figure}{0}

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=\textwidth]{../analysis/all-clean-ts-3.pdf}
\caption{
  All filtered times series used in our analysis. The abundances are shown on
  a log10 vertical axis. Colours indicate taxonomic classes. Open black circles
  indicate abundance values that were interpolated. Closed black circles
  indicate single abundance values that were recorded as zero but were set to
  the next lowest observed abundance.
}
    \label{fig:all-ts}
\end{center}
\end{figure}

\clearpage

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=\textwidth]{../analysis/priors-gomp-base.pdf}
\caption{
  Probability density of the Bayesian priors for the Gompertz models. From left
  to right: (1) per capita growth rate at $\log$(abundance) = $0$: $\lambda \sim
  \mathrm{Normal}(0, 10^2)$; (2) scale parameter of t-distribution process
  noise: $\sigma \sim \mathrm{Half\mhyphen Cauchy} (0,
  2.5)$; (3) t-distribution degrees of freedom parameter: $\nu \sim
  \mathrm{Truncated\mhyphen Exponential}(0.01, \mathrm{min.} = 2)$; (4) AR1
  correlation coefficient of residuals: $\phi \sim \mathrm{Truncated \mhyphen
    Normal}(0, 1, \mathrm{min.} = -1, \mathrm{max.} = 1)$. Not shown is $b$,
  the density dependence parameter: $b \sim \mathrm{Uniform}(-1, 2)$.
}
  \label{fig:priors}
\end{center}
\end{figure}

\clearpage

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=0.9\textwidth]{../analysis/ts-gpdd-heavy-eg-log10-base.pdf}
\caption{
  Time series for populations with Pr($\nu < 10$) $>$ 0.5 using the base
  Gompertz population model. Panels are ordered by increasing Pr($\nu < 10$).
  Vertical axes are on a log10 scale. Colours indicate taxonomic classes. The
  labels on each panel indicate Pr($\nu < 10$) $>$ 0.5, the common name for the
  species, and the Global Population Dynamics Database ID number.
}
\label{fig:heavy-ts}
\end{center}
\end{figure}

\clearpage

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=0.27\textwidth]{../analysis/order-level-estimates.pdf}
\caption{
  Taxonomic-order-level posterior estimates of probability that $\nu < 10$ from
  a beta regression multilevel model accounting for the effect of time-series
  length. Estimates are at the geometric mean of time series length across all
  the data (approximately 27 time steps). Colour shading refers to the
  taxonomic classes as indicated in Fig.~\ref{fig:nu-coefs} and
  Fig.~\ref{fig:correlates} (yellow for fishes, green for insects, purple for
  birds, and red for mammals). Short vertical line segments indicate median
  posterior estimates. Long dotted vertical line throughout the figure
  indicates the median expected Pr($\nu < 10$) from the prior distribution.
}
\label{fig:order-estimates}
\end{center}
\end{figure}

\clearpage

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=\textwidth]{../analysis/gomp-comparison.pdf}
\caption{
  Estimates of $\nu$ from alternative models plotted against the base Gompertz
  model estimates of $\nu$. Shown are medians of the posterior (dots) and 50\%
  credible intervals (segments). The diagonal line indicates a one-to-one
  relationship. Different colours indicate various taxonomic classes. The
  grey-shaded regions indicate regions of disagreement if $\nu = 10$ is taken
  as a threshold of heavy-tailed dynamics. The Gompertz observation error model
  assumes a fixed standard deviation of observation error of $0.2$ on a log
  scale.
}
\label{fig:alt}
\end{center}
\end{figure}

\clearpage

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=0.8\textwidth]{../analysis/t-dist-sampling-sim-prior-exp0point01.pdf}
\includegraphics[width=0.8\textwidth]{../analysis/t-dist-sampling-sim-sigma-prior-exp0point01.pdf}
\caption{
  Testing the ability to estimate $\nu$ (top panels) and the scale parameter of
  the process deviations (bottom panels) for a given number of samples (columns)
  drawn from a distribution with a given true $\nu$ value (rows). The red lines
  indicate the true population value. When a small number of samples are drawn
  there may not be samples sufficiently far into the tails to recapture the
  true $\nu$ value; however, heavy tails are still distinguished from normal
  tails in most cases, even with only 25 or 50 samples.
}
\label{fig:sim-nu}
\end{center}
\end{figure}

\clearpage

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=\textwidth]{../analysis/sim-gompertz.pdf}
\caption{
  Simulation testing the Gompertz estimation model when the process deviation
  draws were chosen so that $\nu$ could be estimated close to the true value
  outside the full population model (``effective $\nu$'' within a CV of 0.2 of
  specified $\nu$). The simulation was run across population $\nu$ values
  (columns) and different scenarios (colours): (1) 100 time steps and no
  observation error, (2) 50 time steps and no observation error, (3) 50 time
  steps and observation error drawn from $\mathrm{Normal} (0, 0.2^2)$ but
  ignored, and (4) 50 time steps with observation error in which the quantity
  of observation error was assumed known. Dashed horizontal lines show the true
  population values; these true values were chosen to represent approximately
  the median values as estimated from the Global Population Dynamics Database.
  Individual dots and lines
  represent a stochastic draws from the true population distribution and
  a model fitting (median and 80\% credible intervals). The panels from top to
  bottom show $1/\nu$, process noise scale parameter $\sigma$, growth rate
  parameter $\lambda$, and the density dependence parameter $b$.
}
\label{fig:sim-gompertz}
\end{center}
\end{figure}

\clearpage

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=\textwidth]{../analysis/sim-gompertz-boxplots.pdf}
\caption{
  The distribution of median estimates from the same simulation as described in
  Fig.~\ref{fig:sim-gompertz}. The boxes show the interquartile range. The
  whiskers extend to $1.5$ times the interquartile range and outliers are shown
  as dots. Note that these distributions represent the output from only 20
  simulation iterations, so there is some level of remaining sampling noise.
  \textit{TODO wondering now if I should run these for more iterations to make
    these less noisy.}
}
\label{fig:sim-gompertz-boxplots}
\end{center}
\end{figure}

\clearpage

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=\textwidth]{../analysis/check-sim-box.pdf}
\caption{
  The probability that $\nu < 10$ (i.e.\ the approximate probability of heavy
  tails) for the same simulation scenarios as shown in
  Fig.~\ref{fig:sim-gompertz} and Fig.~\ref{fig:sim-gompertz-boxplots}. Within
  each scenario the dots represent stochastic draws from the true population
  distributions combined with model fits.
}
\label{fig:sim-prob}
\end{center}
\end{figure}

\clearpage

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=0.5\textwidth]{../analysis/stan-beta-correlates}
\caption{
  Main effect posterior densities for potential correlates of heavy-tailed
  dynamics. The response variable was Pr($\nu < 10$) (approximately the
  probability of heavy tails). The beta regression model was fit on a logit
  scale with random intercepts for taxonomic class, taxonomic order, and
  species. All covariates were standardized by subtracting their mean and
  dividing by twice their standard deviation. Therefore, the coefficient values
  represent the expected effect of a change in two standard deviations of the
  raw input variable on the logit-transformed response variable.
}
    \label{fig:correlate-coefs}
\end{center}
\end{figure}

\clearpage

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=0.70\textwidth]{../analysis/perc-prob-increase-with-n}
\caption{
Expected percent increase in the probability of detecting heavy tails, Pr($\nu
< 10$), with an additional ten time steps of data. These values are based on
the curve shown in Fig.~\ref{fig:correlates}d, which is based on the
coefficient in Fig.~\ref{fig:correlate-coefs}. For example, we have about
a 12\% increased probability of observing heavy tails in a time series that has
60 time steps vs.\ a time series with 50 time steps.
}
\label{fig:perc-inc-p}
\end{center}
\end{figure}

\clearpage

\noindent
Example Stan code for a heavy-tailed Gompertz model with AR1 correlated
residuals and a specified level of observation error. The specific code for used for the various models in our analysis is available at \url{https://github.com/seananderson/heavy-tails}.

\begin{spacing}{1.15}
\begin{footnotesize}
\begin{verbatim}
data {
  int<lower=3> N;              // number of observations
  vector[N] y;                 // vector to hold ln abundance observations
  real<lower=0> nu_rate;       // rate parameter for nu exponential prior
}
parameters {
  real lambda;                 // Gompertz growth rate parameter
  real<lower=-1, upper=2> b;   // Gompertz density dependence parameter
  real<lower=0> sigma_proc;    // process noise scale parameter
  real<lower=2> nu;            // t-distribution degrees of freedom
  real<lower=-1, upper=1> phi; // AR1 parameter
  vector[N] U;                 // unobserved states
  real<lower=0> sigma_obs;     // specified observation error SD
}
transformed parameters {
  vector[N] epsilon;           // error terms
  epsilon[1] <- 0;
  for (i in 2:N) {
    epsilon[i] <- U[i] - (lambda + b * U[i - 1])
                       - (phi * epsilon[i - 1]);
  }
}
model {
  // priors:
  nu ~ exponential(nu_rate);
  lambda ~ normal(0, 10);
  sigma_proc ~ cauchy(0, 2.5);
  phi ~ normal(0, 1);
  // data model:
  for (i in 2:N) {
    U[i] ~ student_t(nu,
                     lambda + b * U[i - 1]
                     + phi * epsilon[i - 1],
                     sigma_proc);
  }
  y ~ normal(U, sigma_obs);
}
\end{verbatim}
\end{footnotesize}

\clearpage
\noindent
Stan code for the multilevel beta regression:
\begin{footnotesize}
\verbatiminput{../analysis/betareg4.stan}
\end{footnotesize}

\clearpage

\noindent
The GPDD IDs used in our analysis.

\begin{footnotesize}
\noindent
{\tt
\input{../analysis/mainids}
}
\end{footnotesize}
\end{spacing}
