\documentclass[12pt]{article}
\usepackage{geometry}
\geometry{verbose, letterpaper, tmargin = 2.54cm, bmargin = 2.54cm,
  lmargin = 2.54cm, rmargin = 2.54cm}
\geometry{letterpaper}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{setspace}
\usepackage{booktabs}
\usepackage{ragged2e}
\usepackage{verbatim}
\usepackage[sectionbib]{chapterbib}
\usepackage{amsmath}
\usepackage{longtable}
\usepackage{multirow}
\usepackage{array}
\usepackage{tabu} % for spacing between rows in longtable
\usepackage{titlesec}
\usepackage{url}
\usepackage{mathtools}
\usepackage{cite}
\usepackage{citesupernumber}

\usepackage{lineno}
\usepackage{xcolor}
\renewcommand\linenumberfont{\normalfont\tiny\sffamily\color{gray}}
\modulolinenumbers[2]

% Linux Libertine:
\usepackage{textcomp}
\usepackage[sb]{libertine}
\usepackage[varqu,varl]{inconsolata}% sans serif typewriter
\usepackage[libertine,bigdelims,vvarbb]{newtxmath} % bb from STIX
\usepackage[cal=boondoxo]{mathalfa} % mathcal
\useosf % osf for text, not math
\usepackage[supstfm=libertinesups,%
  supscaled=1.2,%
  raised=-.13em]{superiors}

\mathchardef\mhyphen="2D % math hyphen

\textheight 22.0cm

\usepackage[round,sectionbib]{natbib}
\bibpunct{(}{)}{;}{a}{}{;}

\setlength\parskip{0.10in}
\setlength\parindent{0in}

% Fix line numbering and align environment
% http://phaseportrait.blogspot.ca/2007/08/lineno-and-amsmath-compatibility.html
\newcommand*\patchAmsMathEnvironmentForLineno[1]{%
  \expandafter\let\csname old#1\expandafter\endcsname\csname #1\endcsname
  \expandafter\let\csname oldend#1\expandafter\endcsname\csname end#1\endcsname
  \renewenvironment{#1}%
     {\linenomath\csname old#1\endcsname}%
     {\csname oldend#1\endcsname\endlinenomath}}%
\newcommand*\patchBothAmsMathEnvironmentsForLineno[1]{%
  \patchAmsMathEnvironmentForLineno{#1}%
  \patchAmsMathEnvironmentForLineno{#1*}}%
\AtBeginDocument{%
\patchBothAmsMathEnvironmentsForLineno{equation}%
\patchBothAmsMathEnvironmentsForLineno{align}%
\patchBothAmsMathEnvironmentsForLineno{flalign}%
\patchBothAmsMathEnvironmentsForLineno{alignat}%
\patchBothAmsMathEnvironmentsForLineno{gather}%
\patchBothAmsMathEnvironmentsForLineno{multline}%
}

% remove numbers in front of sections:
\makeatletter
\renewcommand\@seccntformat[1]{}
\makeatother


\title{Supporting Information:\\Evidence for black-swan events in animal
  populations}

\author{
Sean C. Anderson$^{1,2}$ \and
Trevor A. Branch$^2$ \and
Andrew B. Cooper$^3$ \and
Nicholas K. Dulvy$^1$
}
\date{}

\begin{document}


\input{../analysis/values} % R output

\maketitle

\textsuperscript{1}Earth to Ocean Research Group, Department of Biological
Sciences, Simon Fraser University, Burnaby BC, V5A 1S6, Canada

\textsuperscript{2}School of Resource and Environmental Management, Simon
Fraser University, Burnaby, BC, V5A 1S6, Canada

\textsuperscript{3}School of Aquatic and Fishery Sciences, University of
Washington, Box 355020, Seattle, WA 98195, USA

\linenumbers
\onehalfspacing


%\begin{centering}
%\LARGE
%Supporting Information\\[1.0em]
%\end{centering}


\section{Data selection}

We applied the following data selection and quality-control rules to the
Global Population Dynamics Database (GPDD):

\begin{enumerate}

\item To remove populations with unreliable population indices that could be
  strongly confounded with economics and sampling effort, we removed all
  populations with a sampling protocol listed as \texttt{harvest} as well
  populations with the words \texttt{harvest} or \texttt{fur} in the cited
  reference title.

\item We removed all populations with uneven sampling intervals, i.e.\ we
  removed populations that did not have a constant difference between the
  ``decimal year begin'' and ``decimal year end'' columns.

\item We removed all populations rated as $< 2$ in the GPDD quality assessment
  (on a scale of $1$ to $5$, with $1$ being the lowest quality data)
  \citep[following][]{sibly2005, ziebarth2010}.

\item Populations with negative abundance values were removed. Of the
  populations that remained at the end of our other filtering rules, the
  remaining populations with negative abundances listed were all from time
  series that had been standardized by subtracting the mean and dividing by the
  standard deviation. We verified this by locating the original papers the
  datasets were extracted from: \citet{colebrook1978} for zooplankton and
  \citet{lindstrom1995} for grouse. Since the papers did not include the
  original mean time-series values we could not back transform these data
  points.

\item We filled in all missing time steps with \texttt{NA} values and imputed
  single missing values with the geometric mean of the previous and following
  values. We chose a geometric mean to be linear on the log scale that the
  Gompertz and Ricker-logistic models were fit on.

\item We filled in single recorded values of zero with the lowest non-zero
  value in the time series \citep[following][]{brook2006a}. This assumes that
  single values of zero result from abundance being low enough that censusing
  overlooked individuals that were actually present. We turned multiple zero
  values in a row into \texttt{NA} values. This implies that multiple zero
  values were either censusing errors or caused by emigration. Regardless, our
  population models were fit on a multiplicative (log) scale and so could not
  account for zero abundance. To avoid distorting the original data too
  strongly, we removed populations in which we filled in more than four zeros.

\item We removed all populations without at least four unique values
  \citep[following][]{brook2006a}.

\item We removed all populations with four or more identical values in a row
  since these suggest either recording error or extrapolation between two
  observations.

\item We then wrote an algorithm to find the longest unbroken window of
  abundance (no \texttt{NA}s) with at least $20$ time steps in each population
  time series. If there were any populations with multiple windows of identical
  length, we took the most recent window. This is a longer window than used in
  some previous analyses \citep[e.g.][]{brook2006a}, but since our model
  attempts to capture the shape of the distribution tails, our model requires
  more data.

\item We removed GPDD Main IDs \texttt{20531} and \texttt{10139}, which we
  noticed were duplicates of \texttt{20579} (a heron population).
  \texttt{20579} contained additional years of data not present in
  \texttt{10139}. We removed a limited number of populations from class
  Angiospermopsida and Bacillariophyceae to focus the taxonomy in our analysis
  on animals. We also removed any populations with an \texttt{Unknown}
  taxonomic class.

\item Finally, we removed populations with the following GPDD Main IDs, which
  we discovered were data entry errors when verifying the populations with
  suspected black swans: \texttt{1207} because the 1957 data point was entered
  as 2 but should have been 27 \citep{kendeigh1982}, \texttt{6531} because the
  1978 data point was entered as 7 but should have been 47 \citep{minot1986},
  and \texttt{6566} because some of the data did not match the graph
  \citep{heessen1996}.

\end{enumerate}

\noindent
We provide a supplemental figure of all the time series included in our
analysis and indicate which values were interpolated (non-zero interpolations)
(\percImputedPops\% of populations had at least one point interpolated but
only \percImputedPoints\% of the total observations were interpolated)
(Fig.~\ref{fig:all-ts}). Note that interpolation is highly unlikely to lead to
black-swan detections, since black swans involve extreme increases or
decreases. Table~\ref{tab:stats} shows the final taxonomic breakdown and the
number of populations with interpolated values.

\section{Alternative population models}

We fit four alternative population models to the time-series data to check how
they would influence our conclusions. Our alternative models allowed for
autocorrelation in the residuals, assumed no density dependence, allowed for
observation error, or assumed a Ricker-logistic functional form.

\subsection{Autocorrelated residuals}

We considered a version of the Gompertz model in which an autoregressive
parameter was fit to the process noise residuals:
\begin{align*}
x_t &= \lambda + b x_{t-1} + \epsilon_t\\
\epsilon_t &\sim \mathrm{Student\mhyphen t}(\nu, \phi \epsilon_{t-1}, \sigma).
\end{align*}
In addition to the parameters in the original Gompertz model, this model
estimates an additional parameter $\phi$, which represents the correlation of
subsequent residuals. Based on the results of previous analyses with the GPDD
\citep[e.g.][]{connors2014} and the chosen priors in previous analyses
\citep[e.g.][]{thorson2014a} and to greatly speed up chain convergence when
running our model across all populations, we placed a weakly informative prior
on $\phi$ that assumed the greatest probability density near zero with the
reduced possibility of $\phi$ being near $-1$ or $1$. Specifically, we chose
$\phi \sim \mathrm{Truncated\mhyphen Normal}(0, 1, \mathrm{min.} = -1,
\mathrm{max.} = 1)$. The MCMC chains did not converge for
\modelsNoConvergeAROne\ populations according to our criteria ($\widehat{R} <
1.05, n_\mathrm{eff} > 200$) after 8000 iterations of four chains. This
  included only \modelsNoConvergeAROneHeavyBase\ populations in which Pr($\nu
  < 10$) $> 0.5$ categorized them as heavy in the main Gompertz model. We did
  not include these models in Fig.~\ref{fig:alt}.

\subsection{Assumed density independence}\label{assumed-density-independence}

We fit a simplified version of the Gompertz model in which the density
dependence parameter $b$ was fixed at $1$ (density independent). This is
equivalent to fitting a random walk model (with drift) to the $\log$
abundances or assuming the growth rates are drawn from a stationary
distribution. The model was as follows:
\begin{align*}
x_t &= \lambda + x_{t-1} + \epsilon_t\\
\epsilon &\sim \mathrm{Student\mhyphen t}(\nu, 0, \sigma).
\end{align*}
We fit this model for three reasons: (1) it is computationally simpler and so
provides a check that our more complicated full Gompertz model was obtaining
reasonable estimates of $\nu$, (2) it provides a test of whether density
dependence was systematically affecting our perception of heavy tails, (3) it
matches how some previous authors have modelled heavy tails without accounting
for density dependence \citep{segura2013}.

\subsection{Assumed observation error}

Observation error can bias parameter estimates \citep[e.g.][]{knape2012} and
is known to affect the ability to detect extreme events \citep{ward2007}. In
our main analysis, we fit a model that ignored observation error. One way to
account for observation error would be to fit a full state-space model that
simultaneously estimates the magnitude of process noise and observation error.
However, simultaneously estimating observation and process noise is a
challenging problem (e.g.\ because the observation and process noise
parameters tend to negatively covary in model fitting) and is known to
sometimes result in identifiability issues with the Gompertz population model
\citep{knape2008}. Furthermore, our model was applied to hundreds of time
series, often of short length (as few as 20 time steps) and our model
estimates an additional parameter---the shape of the process deviation
tails---potentially making identifiability and computational issues even
greater. Therefore, we considered a version of the base Gompertz model that
allowed for a fixed level of observation error:
\begin{align*}
U_t &= \lambda + b U_{t-1} + \epsilon_t\\
x_t &\sim \mathrm{Normal}(U_t, \sigma_\mathrm{obs}^2)\\
\epsilon_t &\sim \mathrm{Student\mhyphen t}(\nu, 0, \sigma_\mathrm{proc}),
\end{align*}
where $U$ represents the unobserved state vector, $\sigma_\mathrm{obs}$
represents the standard deviation of observation error (on a log scale), and
$\sigma_\mathrm{proc}$ represent the process noise scale parameter. We set
$\sigma_\mathrm{obs}$ to $0.2$, which represents the upper limit of values
often used in simulation analyses \citep[e.g.][]{valpine2002, thorson2014b}.

\subsection{Ricker-logistic}

We also fit a Ricker-logistic model:
\begin{align*}
x_t &= x_{t-1} + r_{\mathrm{max}}\left(1 - \frac{N_{t-1}}{K}\right) + \epsilon_t\\
\epsilon_t &\sim \mathrm{Student\mhyphen t}(\nu, 0, \sigma),
\end{align*}
where $r_\mathrm{max}$ represents the theoretical maximum population growth
rate that is obtained when $N_t$ (abundance at time $t$) $= 0$. The parameter
$K$ represents the carrying capacity and, as before, $x_t$ represents the
$\log$ transformed abundance at time $t$. The Ricker-logistic model assumes a
linear decrease in population growth rate with increases in abundance. In
contrast, the Gompertz model assumes a linear decrease in population growth
rate with increases in \textit{log} abundance ($x_t$)
\citep[e.g.][]{thibaut2012}.

To fit the Ricker-logistic models, we chose a prior on $K$ uniform between
zero and twice the maximum observed abundance (\citet{clark2010} chose uniform
between zero and maximum observed, which is more informative). We set the
prior on $r_\mathrm{max}$ as uniform between 0 and 20 as in \citet{clark2010}.
We used the same priors on $\nu$ and $\sigma$ as in the Gompertz model.

\section{Implementation of skewed Student t distribution in Stan}

The probability density for the skewed Student t distribution described in the
methods section translates to the log probability:

\[
\mathrm{Skewed\,Student\mhyphen t}(x) =
\begin{dcases}
  \log (2 \gamma) - \log(\gamma^2 + 1) +
  \log \mathrm{Student\mhyphen t}(x \cdot \gamma, \nu, \mu \cdot \gamma, \sigma),& \text{for } x < 0\\
  \log (2 \gamma) - \log(\gamma^2 + 1) +
  \log \mathrm{Student\mhyphen t}(x / \gamma, \nu, \mu / \gamma, \sigma),& \text{for } x \ge 0
\end{dcases}
\]

Since Stan only needs the probability density up to an additive constant, we
can replace $\log(2 \gamma)$ in the above for $\log(\gamma)$. The final log
probability density for the skewed Student's t distribution implemented in
Stan\footnote{See the Stan users mailing list:
\url{https://groups.google.com/d/msg/stan-users/jeZQnQRUsDs/BeqhicWm1GEJ}}
looks like the following:

\begin{verbatim}
real skew_student_t_log(real y, real nu, real mu, real sigma, real skew) {
  real lp;
  lp <- log(skew) - log1p(square(skew));
  if (y < mu)
    return lp + student_t_log(y * skew, nu, mu * skew, sigma);
  else
    return lp + student_t_log(y / skew, nu, mu / skew, sigma);
}
\end{verbatim}

\section{Simulation testing the model}

We performed two types of simulation testing. First, we tested how easily the
Student-t distribution $\nu$ parameter could be recovered given different true
values of $\nu$ and different sample sizes. Second, we tested the ability of
the heavy-tailed Gompertz model to obtain unbiased parameter estimates of
$\nu$ given that a set of process deviations was provided in which the
effective $\nu$ value was close to the true $\nu$ value.

We separated our simulation into these two components to avoid confounding two
issues. (1) With smaller sample sizes, there may not be a stochastic draw from
the tails of a distribution. In that case, no model, no matter how perfect,
will be able to detect the shape of the tails. (2) Complex models may return
biased parameter estimates if there are conceptual, computational, or coding
errors. Our first simulation tested the first issue and our second simulation
tested the latter. In general, our simulations show that, if anything, our
model under predicts the magnitude and probability of heavy tailed
events---especially given the length of the time series in the GPDD.

\subsection{Estimating $\nu$ from a stationary t distribution}

First, we tested the ability to estimate $\nu$ given different true values of
$\nu$ and different sample sizes. We took stochastic draws from t
distributions with different $\nu$ values ($\nu = 3, 5, 10,$ and $10^6$
[$\approx$ normal]), with central tendency parameters of $0$, and scale
parameters of $1$. We started with $1600$ stochastic draws and then fit the
models again at the first $800, 400, 200, 100, 50,$ and $25$ draws. Each time
we recorded the posterior samples of $\nu$.

In the following image, the red lines indicate the true population value. Dots
represent the median estimate the lines represent the 80\% credible interval.
When a small number of samples are drawn there may not be samples sufficiently
far into the tails to recapture the true $\nu$ value; however, heavy tails are
still distinguished from normal tails in most cases, even with only 25 or 50
samples:

\begin{center}
\includegraphics[width=0.8\textwidth]{../analysis/t-dist-sampling-sim-prior-exp0point01.pdf}
\includegraphics[width=0.8\textwidth]{../analysis/t-dist-sampling-sim-sigma-prior-exp0point01.pdf}
\end{center}

We found that we could consistently and precisely recover median posterior
estimates of $\nu$ near the true value of $\nu$ with large samples ($\ge 200$)
(upper panels). At smaller samples we could still usually qualitatively
distinguish heavy from not-heavy tails, but the model tended to underestimate
how heavy the tails were. At the same time, at smaller sample sizes, the model
tended to overestimate how large the scale parameter was (lower panels).

\subsection{Heavy-tailed Gompertz model simulations}

In the second part of our simulation testing, we tested the ability of the
heavy-tailed Gompertz model to obtain unbiased parameter estimates when the
process noise was chosen so that appropriate tail events were present. To
generate these process deviations for the $\nu = 3$ and $\nu = 5$ scenarios,
we repeatedly drew proposed candidate process deviations and estimated the
central tendency, scale, and $\nu$ values each time. We recorded when
$\hat{\nu}$ (median of the posterior) was within $0.2$ CVs (coefficient of
variations) of the true $\nu$ value and used this set of random seed values in
our Gompertz simulation. The following simplified R code illustrates this
procedure (the actual code is available at
\url{https://github.com/seananderson/heavy-tails}):

\begin{footnotesize}
\begin{verbatim}
get_effective_nu_seeds <- function(nu_true = 5, cv = 0.2, N = 50, seed_N = 20) {
  # nu_true: The true nu value
  # cv:      The permitted effective nu coefficient of variation
  # N:       The length of time series
  # seed_N:  The number of seed values to generate
  seeds <- numeric(length = seed_N)
  seed_value <- 0
  for (i in seq_len(seed_N)) {
    nu_close <- FALSE
    while (!nu_close) {
      seed_value <- seed_value + 1
      set.seed(i)
      y <- rt(N, df = nu_true)
      sm <- rstan::stan(... # fit the Stan model here
      med_nu_hat <- median(rstan::extract(sm, pars = "nu")[[1]])
      if (med_nu_hat > (nu_true - cv) & med_nu_hat < (nu_true + cv)) {
        nu_close <- TRUE
        seeds[i] <- seed_value
      }
    }
  }
  seeds
}
nu_3_seeds_N50 <- get_effective_nu_seeds(nu_true = 3)
nu_5_seeds_N50 <- get_effective_nu_seeds(nu_true = 5)
\end{verbatim}
\end{footnotesize}

We then fit our Gompertz models to the simulated datasets with all parameters
(except $\nu$) set near the median values estimated in the GPDD. We repeated
this with $50$ and $100$ samples without observation error, $50$ samples with
observation error ($\sigma_\mathrm{obs} = 0.2$), and $50$ samples with the
same observation error and a Gompertz model that allowed for correctly
specified observation error magnitude. Our results indicate that the Gompertz
model can recapture the true value of $\nu$ when the process noise was chosen
so that appropriate tail events were present (Fig.~\ref{fig:sim-prob} upper
panels). The addition of observation error caused the model to tend to
underestimate the degree of heavy-tailedness. Fitting a model with correctly
specified observation error did not make substantial improvements to model
bias (Fig.~\ref{fig:sim-prob}).

When converting the posterior distributions of $\nu$ into Pr($\nu < 10$), the
models distinguished heavy and not-heavy tails reasonably well
(Fig.~\ref{fig:sim-prob} lower panels). Without observation error, and using a
probability of $0.5$ as a threshold, the model correctly classified all
simulated systems with normally distributed process noise as not heavy tailed.
The model would have miscategorized only one of $40$ simulations at $\nu = 5$
across simulated populations with $50$ or $100$ time steps
(Fig.~\ref{fig:sim-prob}, scenarios 1 and 2 in lower row, second panel from
left). The model would have correctly categorized all cases where the process
noise was not heavy tailed (Fig.~\ref{fig:sim-prob} bottom-right panel) and
all cases where $\nu = 3$ and there was not observation error. With $0.2$
standard deviations of observation error, the model still categorized
\obsErrorNuFivePerc\% of cases as heavy tailed when $\nu = 5$ and all but one
case when $\nu = 3$. Allowing for observation error made little improvement to
the detection of heavy tails. Therefore, we chose to focus on the simpler
model without observation error in the main text, particularly given that the
true magnitude of observation error was unknown in the empirical data.

In the following image, upper panels show the distribution of median
$\widehat{\nu}$ across 20 simulation runs. Lower panels show the distribution
of Pr($\nu < 10$) across 20 simulation runs. We ran the simulations across
three population (``true'') $\nu$ values (3, 5, and $1\cdot 10^9$, i.e.\
approximately normal) and four scenarios: (1) 100 time steps and no
observation error, (2) 50 time steps and no observation error, (3) 50 time
steps and observation error drawn from $\mathrm{Normal} (0, 0.2^2)$ but
ignored, and (4) 50 time steps with observation error in which the quantity of
observation error was assumed known. Within each scenario the dots represent
stochastic draws from the true population distributions combined with model
fits. Underlayed boxplots show the median, interquartile range, and $1.5$
times the interquartile range:

%\begin{figure}[htbp]
\begin{center}
\includegraphics[width=\textwidth]{../analysis/sim-gompertz-median-dist.pdf}
\includegraphics[width=\textwidth]{../analysis/sim-gompertz-p10.pdf}
%\label{fig:sim-prob}
\end{center}
%\end{figure}


\section{Additional acknowledgements}

Many of the silhouette images used in Figs 2, and 3 were obtained from
\texttt{phylopic.org} under Creative Commons licenses. We vectorized the
salmon in Fig.~2. The bird in these figures was obtained
from \texttt{phylopic.org} under a Creative Commons Attribution 3.0 Unported
license with credit to Jean-Raphaël Guillaumin {[}photography{]} and T.
Michael Keesey {[}vectorization{]}). The silhouettes in
Fig.~3 were obtained from the following sources (metadata
obtained with the help of the rphylopic R package,
\url{https://github.com/sckott/rphylopic}):

\LTcapwidth=\textwidth
%\singlespacing
\begin{footnotesize}
\begin{longtable}{>{\RaggedRight}m{3.2cm}>{\RaggedRight}p{6.5cm}>{\RaggedRight}p{5.0cm}}
%\caption{Phylopic credits}\\
\toprule
\input{../analysis/phylopic.tex}
\label{tab:phylopic}
\end{longtable}
\end{footnotesize}
%\onehalfspacing


\bibliographystyle{apalike}
\bibliography{/Users/seananderson/Dropbox/tex/jshort,supp}
%
% ------------------------------
% Supplemental Tables
% ------------------------------

%\clearpage
%\renewcommand{\thetable}{S\arabic{table}}
%\setcounter{table}{0}

% ------------------------------
% Supplemental Figures
% ------------------------------

%\renewcommand{\thefigure}{S\arabic{figure}}
%\setcounter{figure}{0}

% \begin{centering}
% \clearpage
% \includegraphics[width=\textwidth]{../analysis/all-clean-ts-mammals.pdf}\\
% Figure~\ref{fig:all-ts} (mammals) continued on next page \ldots
%
% \clearpage
% \includegraphics[width=\textwidth]{../analysis/all-clean-ts-birds.pdf}\\
% Figure~\ref{fig:all-ts} (birds) continued on next page \ldots
%
% \clearpage
% \includegraphics[width=\textwidth]{../analysis/all-clean-ts-insects.pdf}\\
% Figure~\ref{fig:all-ts} (insects) continued on next page \ldots
%
% \end{centering}

% \begin{figure}[htbp]
% \begin{center}
% \includegraphics[width=\textwidth]{../analysis/all-clean-ts-fishes-others.pdf}
%
% \caption[All filtered time series used in our analysis.]{(fishes, crustaceans,
%   gastropods, sharks). All filtered time series used in our analysis. The
%   abundances are shown on a log10 vertical axis. Throughout this figure, red
%   dots indicate values that were interpolated and blue dots indicate values
%   that were recorded as zero but were set to the next lowest observed
%   abundance. Numbers before each species name are the GPDD Main ID numbers.}
%
% \label{fig:all-ts}
% \end{center}
% \end{figure}

%\clearpage

\clearpage

\noindent
Example Stan code for a heavy-tailed Gompertz model with AR1 correlated
residuals and a specified level of observation error. The specific code for
the various models in our analysis is available at
\url{https://github.com/seananderson/heavy-tails}.

%\begin{spacing}{1.15}
\begin{footnotesize}
\begin{verbatim}
data {
  int<lower=3> N;              // number of observations
  vector[N] y;                 // vector to hold ln abundance observations
  real<lower=0> nu_rate;       // rate parameter for nu exponential prior
}
parameters {
  real lambda;                 // Gompertz growth rate parameter
  real<lower=-1, upper=2> b;   // Gompertz density dependence parameter
  real<lower=0> sigma_proc;    // process noise scale parameter
  real<lower=2> nu;            // t-distribution degrees of freedom
  real<lower=-1, upper=1> phi; // AR1 parameter
  vector[N] U;                 // unobserved states
  real<lower=0> sigma_obs;     // specified observation error SD
}
transformed parameters {
  vector[N] epsilon;           // error terms
  epsilon[1] <- 0;
  for (i in 2:N) {
    epsilon[i] <- U[i] - (lambda + b * U[i - 1])
                       - (phi * epsilon[i - 1]);
  }
}
model {
  // priors:
  nu ~ exponential(nu_rate);
  lambda ~ normal(0, 10);
  sigma_proc ~ cauchy(0, 2.5);
  phi ~ normal(0, 1);
  // data model:
  for (i in 2:N) {
    U[i] ~ student_t(nu,
                     lambda + b * U[i - 1]
                     + phi * epsilon[i - 1],
                     sigma_proc);
  }
  y ~ normal(U, sigma_obs);
}
\end{verbatim}
\end{footnotesize}

\clearpage
\noindent
Stan code for the multilevel beta regression:
\begin{footnotesize}
\verbatiminput{../analysis/betareg4.stan}
\end{footnotesize}

\clearpage

\noindent
The GPDD IDs used in our analysis.

\begin{footnotesize}
%\renewcommand{\baselinestretch}{1.11}
\noindent
{\tt
\input{../analysis/mainids}
}
%\renewcommand{\baselinestretch}{\textstretch}
\end{footnotesize}
\normalsize
%\end{spacing}

\end{document}
