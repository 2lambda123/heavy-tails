\documentclass[10pt]{article}
\usepackage{geometry}
\geometry{letterpaper}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsfonts}
%\usepackage{pdfpages}
%\usepackage{lscape}
%\usepackage{pdflscape}
%\usepackage{setspace}
\usepackage{booktabs}

\usepackage{longtable}
\usepackage{multirow}
\usepackage{array}
\usepackage{ragged2e}
\usepackage{tabu} % for spacing between rows in longtable
\setlength{\tabulinesep}{9pt}

\mathchardef\mhyphen="2D
%\usepackage{url}
%\urlstyle{rm}


\textheight 20.5cm

\usepackage[round]{natbib}
\bibliographystyle{apalike}
\bibpunct{(}{)}{;}{a}{}{;}

\title{The evidence for heavy tails in global\\population dynamics}
\author{Sean Anderson \ldots}
%\date{}

%\pagestyle{empty}
%\setcounter{secnumdepth}{-2}



\begin{document}

\input{values}

%\begin{spacing}{1.1}
%\doublespacing
%\onehalfspacing
\maketitle

\section*{Abstract}


\section*{Introduction}

Increasing realization about the importance of extreme events in the environment (REFs)

and of the importance of ecological surprises and black swans (REFs)

Papers to work in:

\citep{inchausti2002,halley2002,inchausti2001}

\citep{jentsch2007}

\citep{ward2007}

\citep{garcia-carreras2011}
\citep{sornette2009}

\citep{nunez2012}

\citep{thompson2013}
\citep{beaugrand2012}
\citep{pine-iii2009}

\citep{doak2008}

\citep{smale2013}

\citep{easterling2000}
\citep{scheffer2003}
\citep{katz2005}

\citep{taleb2007}

\citep{vasseur2014}

\citep{vert-pre2013}
\citep{lindenmayer2010}

\ldots

citation with good justification of gompertz and other references: \citep{herrandoprez2014}

\section*{Methods}

First, I tried fitting this as a Gompertz model and estimating the density dependence parameter. The Gompertz was by far the most favoured model in \citet{brook2006} with the GPDD.

I could see an argument being made that we're just seeing them because of autocorrelation in the residuals. Autocorrelation plays a big role in \citet{inchausti2002} justifying why they think they're seeing increasing CV of time series in the GPDD with time and an increasing CV could create heavy tails. They just model the spectral properties and CV of the abundance time series --- not a population dynamics model. I tried estimating a coefficient for the first-order autocorrelation of the residuals. There is some autocorrelation it picks up sometimes, but interestingly this doesn't change things that much with respect to heavy tail results. Nothing systematic at least (Another important reference on spectral analysis and the GPDD: \citet{garcia-carreras2011}.)


\subsection*{Modelling framework}

The autoregressive Student-t Gompertz model is:
\begin{align*}
x_t &= \lambda + b x_{t-1} + \epsilon_t\\
\epsilon_t &\sim \mathrm{Student\mhyphen t}_\nu(\phi \epsilon_{t-1}, \sigma_\mathrm{proc}^2),
\end{align*}

\noindent where $x_t$ is the $\ln$ abundance at time $t$ and $\nu$ is the Student-t distribution degrees of freedom parameter. If $\nu$ is small (say 2--20) the distribution has heavy tails. As $\nu$ approaches infinity the distribution approaches the normal distribution. The parameter $b$ is the density dependence parameter. The model is density independent if $b = 1$ and maximally density dependent if $b = 0$. The parameter $\phi$ represent the first-order autoregressive correlation of the residuals $\epsilon$. $\sigma_\mathrm{proc}$ is the process error standard deviation. $\lambda$ represents the population growth rate per time step.

The mostly weakly-informative priors I'm using are:
\begin{align*}
b &\sim \mathrm{Uniform}(-1.2, 1.2)\\
\lambda &\sim \mathrm{Normal}(0, 20^2)\\
\nu &\sim \mathrm{Exponential}(0.01)\\
\phi &\sim \mathrm{Truncated\mhyphen Normal}(0, 1, \mathrm{min.} = -0.99, \mathrm{max.} = 0.99)\\
\sigma_\mathrm{proc} &\sim \mathrm{Half\mhyphen Cauchy} (5).
\end{align*}

Priors justification:

\begin{itemize}
\item $b$ is bounded just past stationary so we can detect if they are non-stationary will keeping the sampler from wandering off

\item $\lambda$ prior (variance = 400) is basically uninformative within the range of expected values for population growth... it allows even a X probability at a value of X

\item $\nu$ is based on \citet{fernandez1998}; they chose a more informative 0.1 value, we chose a less informative 0.01 and justify it based on performance in supplemental figure X (gives X probability of value less than 10) but constrains the sampling somewhat since above 40 or 50 the shape of the t distribution is almost identical and data are not usually informative at these data quantities... sampler would head off to infinity otherwise

\item $\phi$ given a standard deviation of 1 given prior analyses which suggest autocorrelation in these datasets is minimal; prior is weak enough to allow high or low values, but given little information will stay near our expectation; similar approach in \citep{thorson2014a}

\item $\sigma_\mathrm{proc}$ can be justified based on \citet{gelman2006c} and the expected range of this variable in nature from previous studies \citep[e.g.][]{connors2014}
\end{itemize}

Using Stan 2.4.0 \citep{stan-manual2014}, and R 3.1.1 \citep{r2014} I'm starting with 4 chains and 2000  iterations with the first 1000 as warmup (i.e.\ 4000 total samples). If rhat is greater than 1.05 for any parameter or the minimum effective sample size is less than 200 for any parameter then I double both the total iterations and warmup and run again. These conditions were met by 8000 iterations (16000 total samples) in all cases and in almost all cases (X\%) within the initial 2000 iteration case (i.e.\ a total of 8000 samples).

Then, I again tried allowing for a specified level of observation error. I'm still running that now for just the mammals. From before, I believe this will reduce the probability of heavy tails a bit for many of them, but the vast majority that had heavy tails would still be considered heavy tailed. This does reduce substantially many of the bird heavy tails though.

(See the simulation results... I don't think this has the intended benefit and can probably be left out of the main results.)

When I incorporate observation error, the model is:
\begin{align*}
U_t &= \lambda + b U_{t-1} + \epsilon_t\\
x_t &\sim \mathrm{Normal}(U_t, \sigma_\mathrm{obs}^2)\\
\epsilon_t &\sim \mathrm{Student\mhyphen t}_\nu(\phi \epsilon_{t-1}, \sigma_\mathrm{proc}^2),
\end{align*}

\noindent
where $U$ represents the unobserved state vector, and $\sigma_\mathrm{obs}$ represents the standard deviation of observation error (on a log scale), which was set at 0.2.


%Also, we may not be crazy seeing the heavier tails for heavier longer lived animals. There's some precedence for that in a paper that found more red noise (longer term fluctuations dominating the variance and therefore making the CV grow with time) in large-bodied animals. They attributed it to a mismatch between dynamics and the observation scale. They used a different life-history dataset too. But, there are other systematic differences with the body size-nu relationship that make this sketchy for us. E.g.\ taxonomic orders and interval frequency of data collection vary systematically and in clumps with body size (not shown in the below figure). And basically the only stuff with very \textit{low} probability of heavy tails are the the small ones with generation times less than a year and small collection intervals. It's basically a step function. We may not be able to tease that all apart... at least not in this paper.

\subsection*{Data selection}

Filtering rules for the GPDD:
We removed all populations with zeros (can't be fit with a Gompertz), all populations with uneven sampling intervals (end date minus start date for each step), and all populations with population estimates listed as ``harvest'' as well as those listed as from two fur trading sources (give details).
Then, we removed any populations with 5 or more identical values in a row since these suggest either recording error or extrapolation between two observations.
Then, we filled in all missing time steps with NAs and imputed single missing values with the geometric mean of the previous and following values (linear on the log scale that the Gompertz operates on). This leaves NAs that were recorded in successive time steps.
Then, we went through each population time series and found the longest window of abundance with at least 25 time steps. If there were any with multiple windows of identical length, we took the most recent window.
Finally, we removed main\_id 20531, which is a duplicate of 10139 (a heron population) and main\_id 10008, which had obvious errors in the data recording (a water vole population). We provide a supplemental figure of all the time series included in our analysis and indicate which values were imputed (\percImputedPops\% of populations had at least one point imputed and only \percImputedPoints\% of the total observations were imputed) (Fig.\ SX).


\subsection*{Simulation testing the model}

Throughout all of this --- show that the model, if anything, under-predicts heavy tails but with sufficient data is unbiased.

2 parts: how many samples from the true population t distribution do you need to detect low nu? And, given that you have a set of deviations in which nu is detectable (effective nu is within 0.5 CV of true nu), can the more complex Gompertz still capture this?

First part: We drew from t distributions with different nu values and mean of 0, scale of 1. We started with 1600 samples and then fitted again at the first 800, 400, 200,  100, 50, 25. Each time we recorded the nu posterior.

Second part: To generate a series of process deviations with an effective nu approximately equal to the true nu, we generated process deviation sets repeatedly and estimated the mean, scale, and nu values each time. We recorded when the estimated nu was within 0.5 CVs of the true nu and used this set of random seed values in our Gompertz simulation. We then fit AR1 Gompertz models to the simulated datasets with all parameters (except nu) set near the median values estimated in the GPDD.

\section*{Results}

Main text figures:

\begin{enumerate}
\item illustrate $\nu$ and show simulated Gompertz time series with these levels of $\nu$ (include probability density at some extreme deviation in the caption or on figure for different $\nu$ values

\item a figure showing $\nu$ estimates within classes and  orders, ordered by decreasing $\nu$ estimate to illustrate percentage of populations, grouped by order in a phylogenetically related way include some silhouettes

\item 5--10 example time series with heavy tails from the GPDD; highlight the ``black swans'' with, say, red dots (perhaps also highlighting if they are up or down swings); pick some \textit{very} heavy tails and some moderately heavy tails. Show the $\nu$ estimate somewhere in each panel

\item something looking at hypotheses for what's associated with heavy tails: data collection method, mid date of time series (or when it started?), time series length, AR1, density dependence, lambda, body size for mammals, IUCN status? Most likely a grid of scatter plots coloured by taxonomic class.... or rows by taxonomic class and colours by order. (also ratio of generation time to collection window) (possibly, some of these will go in supplement with interesting ones in main paper).

\end{enumerate}

Main text tables:

\begin{enumerate}
\item Table summarizing hypotheses for why we might see heavy tails
\item Pick some example populations (say the ones in the time series example plot) and show the nu estimate, reference, and a column digging into any known caveats or reasons
\end{enumerate}

Supplemental figures:

\begin{enumerate}


\item illustration of how the exponential prior slightly constrains the sampling of $\nu$\ldots illustrating what the prior probability of heavy tails is given uninformative data (about 5\% probability $\nu < 10$.

\item plots of the priors overlayed with estimates across populations for all parameters

\item cross plot of $\nu$ estimates from the models: no density dependence, add density dependence, add AR1, add assumed observation error

\item time series plots of all heavy-tailed populations

\item simulation testing of detecting nu given reduced sampling from true distribution; show repeated estimates of nu with different sample sizes, and show a few example samples with different observation window lengths and highlight the deviations that are beyond the 0.001 and 0.999 probabilities for a normal distribution.

\item simulation testing of the Gompertz model with process error deviations fixed to have an effective $\nu$ estimate at the true level --- this asks how well is the Gompertz model able to partition the various parameters in a precise and unbiased way given that we know the heavy tails are there (also include a scenario with a massive black swan to show how it behaves there)

\end{enumerate}

\section*{Discussion}

- why we think we see them in some taxa but not others (observation scale dynamics mismatch; observation errors...)

Ways forward:

- hierarchical modelling of nu and other parameters

- better datasets for specific taxa (e.g.\ fish recruitment)

- joint prior on scale and nu parameters

- diving much deeper into what heavy tails are associated with

- do heavy tails have conservation importance?

- can we forecast their probability and develop correlates?

- how can we detect them relatively quickly after they happen?

- how often are heavy tails real? observation error, recording errors...

- what does this mean for how we model time series (should we consider using the t as a default even if we fix nu?)

- what does this mean for conservation management (probability of crash  might be higher than our typical models tell us)

\bibliography{/Users/seananderson/Dropbox/tex/jshort.bib,/Users/seananderson/Dropbox/tex/ref3.bib}

\clearpage

\section{Tables}


\LTcapwidth=\textwidth
\bibpunct{}{}{;}{a}{}{;}

\begin{small}
\begin{longtable}{>{\RaggedRight}m{2.0cm}>{\RaggedRight}p{3.0cm}>{\RaggedRight}p{7.0cm}>{\RaggedRight}p{2.0cm}}

\caption{TODO}\\

\toprule
Time series & Species & Black swan description & Reference \\
\midrule

\includegraphics[width=2cm]{sparks/6528} &
Shag (\textit{Phalacrocorax aristotelis}), Northumberland &
Shortage of nest sites reduced productivity; red-tide event in 1968 caused extreme mortality; no longer a nest shortage; population rapidly increased. &
\citep{potts1980}\\

%\includegraphics[width=2cm]{sparks/9675} &
%Carrot fly (\textit{Psila rosae}, Finland &
%TODO &
%\citep{markkula1965}\\

%\includegraphics[width=2cm]{sparks/10139} &
%Grey heron (\textit{Ardea cinerea}), UK &
%TODO &
%\citep{stafford1971}\\

\includegraphics[width=2cm]{sparks/1235} &
Wren (\textit{Troglodytes troglodytes}), UK &
TODO &
REF \\

%\includegraphics[width=2cm]{sparks/20580} &
%Chamois, \textit{Rupicapra rupicapra}, Switzerland &
%TODO &
%\citep{brook2006a}\\

\includegraphics[width=2cm]{sparks/5019} &
Barbary macaque, TODO &
TODO &
REF\\

\bottomrule
\label{tab:sparks}
\end{longtable}
\end{small}

\clearpage


\include{stat-table}
%\bibpunct{}{}{;}{a}{}{;}
%\begin{footnotesize}
%
%\renewcommand*{\arraystretch}{1.5}
%\begin{longtable}{>{\RaggedRight}p{3.5cm}>{\RaggedRight}p{8.2cm}>{\RaggedRight}p{2.2cm}}
%
%\caption{Description of black swans in GPDD}\\
%\toprule
%
%\midrule
%
%\bottomrule
%\label{tab:causes}
%\end{longtable}
%\end{footnotesize}
%\bibpunct{(}{)}{;}{a}{}{;}








\section{Figures}

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=0.6\textwidth]{t-nu.pdf}
\caption{A figure illustrating $\nu$. Maybe put some example (Gompertz) time series to the right with the same seed and different $\nu$ values?}
\label{default}
\end{center}
\end{figure}

\clearpage

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=\textwidth]{gomp-nu-ar1.pdf}
\caption{Estimate of $\nu$ from the Gompertz model (with estimated AR1 autocorrelation of the residuals but no observation error). Shown are median (points), quartiles (mid line segments) and 90\% quantiles (widest line segments) of the posterior.}
\label{fig:nu-coefs}
\end{center}
\end{figure}

\clearpage

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=\textwidth]{gomp-ar1-p20-dot-order.pdf}
\caption{Probability $\nu<20$, i.e.\ one way of asking what the probability is of heavy tails. Dots represent populations. Something like this could be made more pretty and sorted in some appropriate way\ldots maybe with little silhouettes for the animals. Looks pretty similar for $\nu < 10$, with the probabilities a bit lower. There is some vertical jitter added. Could do this and have another subpanel that breaks down the mammals by family, since there's the most interesting stuff happening there and there are lots of them... or just colour the dots by family within each panel.}
\label{fig:dots}
\end{center}
\end{figure}

%\clearpage
%
%\begin{figure}[htbp]
%\begin{center}
%\includegraphics[width=\textwidth]{gomp-ar1-p20-hist.pdf}
%\caption{Histogram of the same data as Figure~\ref{fig:dots} but lumped by class. Probably can't justify including this as well as the previous two figures unless there's some way we can make this more informative.}
%\label{default}
%\end{center}
%\end{figure}

%\clearpage

%\begin{figure}[htbp]
%\begin{center}
%\includegraphics[width=0.9\textwidth]{effect-of-ar1-on-nu.pdf}
%\caption{The effect of assuming no autocorrelation of residuals (vertical axis) vs.\ estimating autocorrelation of residuals (horizontal axis). I don't see a systematic effect. These are medians and interquartile ranges of the posterior. The colour shows $\phi$ --- the parameter estimating the lag-1 correlation of the residuals. The diagonal line illustrates 1:1. A few of these look strange (ones with $\phi$ near zero but far from the 1:1 line). It's possible the chains haven't converged sufficiently in these cases in one of the model versions. I will check what's going on and run more iterations in a final run if needed.}
%\label{default}
%\end{center}
%\end{figure}

\clearpage

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=\textwidth]{nu-covariates.pdf}
\caption{(Also see the next figure.) A number of hypotheses for what could be driving $\nu$ values. From top left to bottom right: $\phi$ (AR1 coefficient), $\log \sigma_\mathrm{proc}$ (log process error standard deviation), $N$ (time series length), $b$ (density dependence parameter in the Gompertz model; 1 is density independent and 0 is maximally density dependent), $\lambda$ (growth parameter from Gompertz model), $\log M$ (log adult body mass in grams; just for mammals and from the PanTHERIA database). All dots show median estimates and vertical line segments show interquartile range of posterior for the $\nu$ values. I don't generally see a whole lot going on here besides taxonomic differences but I'm open to some eye fuzzing and other ideas. If we want to, I was playing with a hierarchical beta regression with different levels for the taxonomic orders explaining the variation in p(nu $<$ 10) or these data\ldots but hypothesis generation with some visuals might be enough for this paper.}
\label{default}
\end{center}
\end{figure}

\clearpage

%\begin{figure}[htbp]
%\begin{center}
%\includegraphics[width=\textwidth]{nu-covariates-p.pdf}
%\caption{Same as previous figure but the y axis is p(nu $<$ 20), which I think might be better to use\ldots, in reality this kind of coarse dichotomy I think is more realistic. If p(nu $<$ 20) is high (say above 0.5) then there's a good chance the tails are heavy. Otherwise, we just don't know.}
%\label{default}
%\end{center}
%\end{figure}


%\begin{figure}[htbp]
%\begin{center}
%\includegraphics[width=0.7\textwidth]{p10-mammals-cross.pdf}
%\caption{Probability that nu $<$ 10 vs.\ log10(body mass) and log10(years at sexual maturity).}
%\label{default}
%\end{center}
%\end{figure}

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=\textwidth]{ts-gpdd-heavy-eg-log10-no-fur.pdf}
\caption{Time series for populations with p(nu $<$ 10) $>$ 0.5. Ordered by increasing p(nu$<$10) (this value is shown pasted onto the front of each panel label). These are shown on a log10 y axis. There are a few funny time series we may want to look into and consider rules to remove. Colours show taxonomic class. This is for our understanding and a version of this could be a supplemental figure. But, we could take maybe 6 to 8 of these and use them as illustrations in the paper with the heavy tailed deviations highlighted. Could also probably dig into the literature on some of these and summarize in a table if we narrowed it down a bit. Lots of minks, beavers, and bears.}
\label{default}
\end{center}
\end{figure}

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=\textwidth]{t-dist-sampling-sim-prior-exp0point01.pdf}
\includegraphics[width=\textwidth]{t-dist-sampling-sim-sigma-prior-exp0point01.pdf}
\caption{TODO --- also maybe show the different exponential priors.}
\label{default}
\end{center}
\end{figure}

\clearpage

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=1.1\textwidth]{sim-gompertz.pdf}
\caption{\textbf{TODO Caption doesn't match new figure.} Results from a simulation test of the estimation model. Dashed horizontal lines are the true population value. True values were chosen to represent approximately the median values as estimated from the GPDD. ``Iteration'' refers to a stochastic draw from the true population distribution and a model fitting. The panels show true values of $\nu = $ 2.1, 5, 15, and 200 (very heavy, heavy, slightly heavy, and not heavy tailed). The panels from top to bottom show nu (red), process error standard deviation (blue), growth parameter (green), density dependence parameter (purple), and autocorrelation parameter (orange). The larger blocks of panels show four scenarios: (1) N = 100, (2) N = 50, (3) N = 50 with ignored observation standard deviation of 0.2, and (4) a model where the model also allows for observation standard deviation of 0.2
In general, this looks fairly good, with the caveat that if the tails are heavy, the model tends to overestimate process error standard deviation and underestimate just how heavy the tails are --- it's a bit biased towards calling heavy tails not as heavy as they are. Also, density independence gets consistently underestimated (purple). Observation error erodes the heavy-tail signal unless the tails are very heavy but doesn't tend to create false positives. Trying to allow for assumed observation error doesn't do much good besides fixing some very subtle bias in the process error estimate when the tails aren't heavy. We'd need a larger observation error to see this clearly. Line segments are 90\% quantiles of the posterior and the dots are the medians.}
\label{default}
\end{center}
\end{figure}

\begin{figure}[htbp]
\begin{center}
\includegraphics[width=\textwidth]{check-sim-box.pdf}
\caption{Same data as previous figure but here represented as probability that nu is less than 10. Basically, this is looking at sensitivity/specificity. So, if you take something like a p = 0.5 that nu $<$ 10 as a cutoff, then you very rarely if ever get a false positive. However, the method doesn't \textit{always} detect heavy tails when they're there\ldots although in our data there are often tails that are much heavier than the nu = 2.5 used here.}
\label{default}
\end{center}
\end{figure}



% \begin{figure}[htbp]
%\begin{center}
%\includegraphics[width=0.6\textwidth]{effect-of-obs-on-nu.pdf}
%\caption{Effect of assuming that observation error is normally distributed (on a log scale) with standard deviation of 0.2.}
%\label{default}
%\end{center}
%\end{figure}
%

%\end{spacing}
\end{document}


little evidence for benefit of including annual climate or climate extremes with these data:
\citep{gregory2010}
and little evidence for allee effect with them

the natural logorithm versino of the logistic is often convenient for parameter estimation
\citep{valpine2002} (and tthey cite a couple people too)
